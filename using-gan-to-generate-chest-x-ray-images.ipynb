{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":7064161,"sourceType":"datasetVersion","datasetId":4067260}],"dockerImageVersionId":30497,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.datasets import mnist\nimport cv2\nimport os\nimport pathlib\nfrom keras.layers import Conv2D, Conv2DTranspose, Dropout, Dense, Reshape, LayerNormalization, LeakyReLU\nfrom keras import layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import f1_score, recall_score, precision_score","metadata":{"id":"WbCwFJD3nJwE","execution":{"iopub.status.busy":"2023-11-26T11:56:30.769837Z","iopub.execute_input":"2023-11-26T11:56:30.770699Z","iopub.status.idle":"2023-11-26T11:56:30.776471Z","shell.execute_reply.started":"2023-11-26T11:56:30.770657Z","shell.execute_reply":"2023-11-26T11:56:30.775359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The following study presents a model for generating chest X-ray images of normal subjects (without lung disease) and pneumonia patients.\n- Through the proposed model, I tried to avoid most of the problems that the GAN models suffer from, in terms of the difficulty of training each of the generator and the discriminant, in addition to the problem of the modal collapse and the perceptual quality, so that I tried through the proposed model, to try to continue the training (to ensure the continuity of the derivability of cost function ) and discovering the features by the discriminator (the most accurate features for each case of the dataset), which leads the generator to focus on them during the training process.\n- A conditional model was used for the GAN, and the discriminator was forced to determine whether the medical images are real or not, in addition to identifying the pathological condition in the generated images.\n- I used (64, 64, 3) images because I didn't have enough computational resources.\n- I used Google Colab For Training.\n- Reading the images included in the dataset, which is for the sound health condition, and the other case, which is pneumonia.\n- I have included all medical images included in each class, although the number of samples per class varies (thus this would require training for a higher number of Epochs for the GAN).","metadata":{"id":"pzM1_nIE9L4u"}},{"cell_type":"code","source":"class ReadDataset:\n    def __init__(self, datasetpath, labels, image_shape):\n        self.datasetpath = datasetpath\n        self.labels = labels\n        self.image_shape = image_shape\n    def returListImages(self,):\n        self.images = []\n        for label in self.labels:\n            self.images.append(list(pathlib.Path(os.path.join(self.datasetpath,\n                                                              label)).glob('*.*')))\n    def readImages(self,):\n        self.returListImages()\n        self.finalImages = []\n        labels = []\n        for label in range(len(self.labels)):\n            for img in self.images[label]:\n                img = cv2.imread(str(img))\n                img = cv2.resize(img , self.image_shape)\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img  = img/255\n                self.finalImages.append(img)\n                labels.append(label)\n        images = np.array(self.finalImages)\n        labels = np.array(labels)\n        return images, labels","metadata":{"id":"Wdb5eGy6nJwH","execution":{"iopub.status.busy":"2023-11-26T09:51:50.585015Z","iopub.execute_input":"2023-11-26T09:51:50.585611Z","iopub.status.idle":"2023-11-26T09:51:50.595062Z","shell.execute_reply.started":"2023-11-26T09:51:50.585583Z","shell.execute_reply":"2023-11-26T09:51:50.594197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"readDatasetObject = ReadDataset('/kaggle/input/chest-xray-pneumonia/chest_xray/train',\n                               ['NORMAL', 'PNEUMONIA'],\n                               (64, 64))\nimages, labels = readDatasetObject.readImages()","metadata":{"id":"G0RqasWvnJwI","execution":{"iopub.status.busy":"2023-11-26T09:51:50.596213Z","iopub.execute_input":"2023-11-26T09:51:50.596497Z","iopub.status.idle":"2023-11-26T09:53:37.939622Z","shell.execute_reply.started":"2023-11-26T09:51:50.596474Z","shell.execute_reply":"2023-11-26T09:53:37.938769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape, labels.shape","metadata":{"id":"XhfehYH_nJwJ","outputId":"ceec17ae-cf12-4653-a4df-d81aa804dc05","execution":{"iopub.status.busy":"2023-11-26T09:53:37.942180Z","iopub.execute_input":"2023-11-26T09:53:37.942859Z","iopub.status.idle":"2023-11-26T09:53:37.949554Z","shell.execute_reply.started":"2023-11-26T09:53:37.942822Z","shell.execute_reply":"2023-11-26T09:53:37.948703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sample images included in the dataset for each class","metadata":{"id":"NtKkpCB2-PBg"}},{"cell_type":"code","source":"plt.figure(figsize = (12, 12))\nindexs = np.random.randint(0, len(labels), size = (64, ))\nfor i in range(64):\n    plt.subplot(8, 8, (i + 1))\n    plt.imshow(images[indexs[i]])\n    plt.title(labels[indexs[i]])\nplt.legend()","metadata":{"id":"elJLaDXtnJwK","outputId":"f329bebb-56d7-4073-8698-49b79c9e39fb","execution":{"iopub.status.busy":"2023-11-26T09:53:37.950888Z","iopub.execute_input":"2023-11-26T09:53:37.951804Z","iopub.status.idle":"2023-11-26T09:53:46.658353Z","shell.execute_reply.started":"2023-11-26T09:53:37.951773Z","shell.execute_reply":"2023-11-26T09:53:46.657345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The proposed generative adversarial network, so that the difficulty of training and many of the problems that can be encountered in the generative adversarial network can be avoided, such as postural collapse and cognitive quality.\n\n- The structure focused on including many structures that helped some of them to avoid falling into the problem of situational collapse, and the other structures focused on perceptual quality (as it forced the distinguished network to focus more on the deeper features in the medical images, which helped the generator to capture them in the generation process).\n\n- The architecture helped make the training balanced between both the Generator and the Discriminator.\n\n- Conditional generation was used, whereby the Discriminator was forced to verify that the generated images were real, class-following (a healthy person, or a person with pneumonia).\n\n- The generator's input was a noise with a regular distribution, in addition to the pathological condition that we want to classify.\n- Use the MSE loss function to address the problem of cognitive quality and make the generator focus on the health characteristics of a healthy person, and the pathological characteristics of a person suffering from pneumonia.","metadata":{"id":"7xIo4CkG_sb1"}},{"cell_type":"code","source":"class Acgan:\n    def __init__(self, eta, batch_size, epochs, weight_decay, latent_space,\n                 image_shape, kernel_size):\n        self.eta = eta\n        self.batch_size = batch_size\n        self.epochs = epochs\n        self.weight_decay = weight_decay\n        self.latent_space = latent_space\n        self.image_shape = image_shape\n        self.kernel_size = kernel_size\n    def data(self, images, labels):\n        ytrain = tf.keras.utils.to_categorical(labels)\n        self.images = images\n        self.labels = ytrain\n    def samples(self, G, noize, labels):\n        images = G.predict([noize, labels])\n        ys = np.argmax(labels, axis = 1)\n        plt.figure(figsize = (12, 4))\n        for i in range(16):\n            plt.subplot(2, 8, (i + 1))\n            plt.imshow(images[i], cmap = 'gray')\n            plt.title(ys[i])\n        plt.show()\n    def generator(self, inputs, labels):\n        filters = [256, 128, 64, 32]\n        padding = 'same'\n        x = inputs\n        y = labels\n        x = layers.concatenate([x, y])\n        x = layers.Dense(1024, )(x)\n        x = layers.Dense(8*8*filters[0],\n                         kernel_regularizer = tf.keras.regularizers.L2(0.001))(x)\n        x = layers.Reshape((8, 8, filters[0]))(x)\n        for filter in filters:\n            if filter >= 64:\n                strides = 2\n            else:\n                strides = 1\n            x = LayerNormalization()(x)\n            x = layers.Activation('relu')(x)\n            x = Conv2DTranspose(filter, kernel_size = self.kernel_size, padding = padding,\n                      strides = strides)(x)\n        x = Conv2DTranspose(3, kernel_size = self.kernel_size, padding = padding)(x)\n        x = layers.Activation('sigmoid')(x)\n        self.generatorModel = models.Model(inputs = [inputs, labels],\n                                           outputs = x,\n                                           name = 'generator')\n    def discriminator(self, inputs):\n        x = inputs\n        filters = [32, 64, 128, 256]\n        padding = 'same'\n        for filter in filters:\n            if filter < 256:\n                strides = 2\n            else:\n                strides = 1\n            x = Conv2D(filter, kernel_size = self.kernel_size, padding = padding,\n                      strides = strides,\n                      kernel_regularizer = tf.keras.regularizers.L2(0.001))(x)\n            x = LeakyReLU(alpha = 0.2)(x)\n        x = layers.Flatten()(x)\n        outputs = Dense(1, )(x)\n        labelsOutput = Dense(256,\n                             kernel_regularizer = tf.keras.regularizers.L2(0.001))(x)\n        labelsOutput = Dropout(0.3)(labelsOutput)\n        labelsOutput = Dense(2,)(labelsOutput)\n        labelsOutput = layers.Activation('softmax')(labelsOutput)\n        self.discriminatorModel = models.Model(inputs = inputs,\n                                               outputs = [outputs, labelsOutput],\n                                               name = 'discriminator')\n    def build(self,):\n        generatorInput = layers.Input(shape = (self.latent_space))\n        discriminatorInput = layers.Input(shape = (self.image_shape))\n        labelsInput = layers.Input(shape = (2, ))\n        self.generator(generatorInput, labelsInput)\n        self.discriminator(discriminatorInput)\n        G = self.generatorModel\n        D = self.discriminatorModel\n        D.compile(loss = ['mse', 'binary_crossentropy'],\n                 optimizer = tf.keras.optimizers.RMSprop(learning_rate = self.eta,\n                                                        weight_decay = self.weight_decay))\n        D.summary()\n        G.summary()\n        D.trainable = False\n        GAN = models.Model(inputs = [generatorInput, labelsInput],\n                           outputs = D(G([generatorInput, labelsInput])))\n        GAN.compile(loss = ['mse', 'binary_crossentropy'],\n                   optimizer = tf.keras.optimizers.RMSprop(learning_rate = self.eta*0.5,\n                                                          weight_decay = self.weight_decay*0.5))\n        GAN.summary()\n        return G, D, GAN\n    def trainAlgorithm(self, G, D, GAN):\n        for epoch in range(self.epochs):\n            indexs = np.random.randint(0, len(self.images), size = (self.batch_size, ))\n            realImages = self.images[indexs]\n            realLabels = self.labels[indexs]\n            realTag = tf.ones(shape = (self.batch_size, ))\n            noize = tf.random.uniform(shape = (self.batch_size,\n                                              self.latent_space), minval = -1,\n                                     maxval = 1)\n            fakeLabels = tf.keras.utils.to_categorical(np.random.choice(range(2), size = (self.batch_size)),\n                                                      num_classes = 2)\n            fakeImages = tf.squeeze(G.predict([noize, fakeLabels], verbose = 0))\n            fakeTag = tf.zeros(shape = (self.batch_size, ))\n            allImages = np.vstack([realImages, fakeImages])\n            allLabels = np.vstack([realLabels, fakeLabels])\n            allTags = np.hstack([realTag, fakeTag])\n            _, dlossTag, dlossLabels = D.train_on_batch(allImages, [allTags, allLabels])\n            noize = tf.random.uniform(shape = (self.batch_size,\n                                              self.latent_space), minval = -1,\n                                     maxval = 1)\n            _, glossTag, glossLabels = GAN.train_on_batch([noize, fakeLabels], [realTag, fakeLabels])\n            if epoch % 5000 == 0:\n                print('Epoch: {}'.format(epoch))\n                print('discriminator loss: [tag: {}, labels: {}], generator loss: [tag: {}, labels: {}]'.format(dlossTag,\n                                                                                                                dlossLabels,\n                                                                                                                glossTag,\n                                                                                                                glossLabels))\n                self.samples(G, noize, fakeLabels)","metadata":{"id":"hSD9skVjnJwL","execution":{"iopub.status.busy":"2023-11-26T09:53:46.659957Z","iopub.execute_input":"2023-11-26T09:53:46.660536Z","iopub.status.idle":"2023-11-26T09:53:46.689098Z","shell.execute_reply.started":"2023-11-26T09:53:46.660507Z","shell.execute_reply":"2023-11-26T09:53:46.688092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In order to avoid falling into the problem of mode collapse, a smaller number of samples was used to be passed each time to the generative adversarial network.\n- It helped reduce the number of samples that are passed to the obstetric adversarial network, until the generator collects more accurately the areas that affect the presence of pneumonia in the patient, as well as the healthy condition.","metadata":{"id":"N7ienCx_AMYO"}},{"cell_type":"markdown","source":"- Because I didn't have much computational resources, not many Epochs were used.","metadata":{"id":"Lp6PA-wdAdT4"}},{"cell_type":"markdown","source":"- Since we are dealing with a pathological condition, the use of kernel_size in a larger size helps to study the relationship between the core regions and the surrounding areas, and the possibility of the existence of gradients that express the pathological condition or the healthy condition. (That is, it helps to determine whether an area, according to its location, can be suitable as a criterion for the presence of pneumonia, or not).\n- Using LayerNormalization instead of BatchNormalization was very useful in diversifying the images that the generator generates and not falling into mode collapse (since LayerNormalization does the normalization at the level of the filters included in the layer).","metadata":{"id":"nFztjRc5BiYh"}},{"cell_type":"code","source":"acgan = Acgan(eta = 0.0001, batch_size = 32, epochs = 32000, weight_decay = 6e-9,\n              latent_space = 100, image_shape = (64, 64, 3), kernel_size = 5)","metadata":{"id":"9VzTLEeRnJwM","execution":{"iopub.status.busy":"2023-11-26T09:53:46.690372Z","iopub.execute_input":"2023-11-26T09:53:46.691067Z","iopub.status.idle":"2023-11-26T09:53:46.702272Z","shell.execute_reply.started":"2023-11-26T09:53:46.691032Z","shell.execute_reply":"2023-11-26T09:53:46.701529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acgan.data(images, labels)","metadata":{"id":"d1OqLus_nJwM","execution":{"iopub.status.busy":"2023-11-26T09:53:46.703258Z","iopub.execute_input":"2023-11-26T09:53:46.703536Z","iopub.status.idle":"2023-11-26T09:53:46.716466Z","shell.execute_reply.started":"2023-11-26T09:53:46.703513Z","shell.execute_reply":"2023-11-26T09:53:46.715546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G, D, GAN = acgan.build()","metadata":{"id":"_sQkxcWunJwN","outputId":"70a352c8-2da5-4ee7-c2f9-e0d42baf30c4","execution":{"iopub.status.busy":"2023-11-26T09:53:46.717728Z","iopub.execute_input":"2023-11-26T09:53:46.718119Z","iopub.status.idle":"2023-11-26T09:53:50.200653Z","shell.execute_reply.started":"2023-11-26T09:53:46.718060Z","shell.execute_reply":"2023-11-26T09:53:50.199784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(GAN, show_shapes = True)","metadata":{"id":"8VsRcRcFnJwN","outputId":"c306c604-642e-4c64-d9fb-ac86e4d2bf5e","execution":{"iopub.status.busy":"2023-11-26T09:53:50.204349Z","iopub.execute_input":"2023-11-26T09:53:50.204722Z","iopub.status.idle":"2023-11-26T09:53:50.349421Z","shell.execute_reply.started":"2023-11-26T09:53:50.204691Z","shell.execute_reply":"2023-11-26T09:53:50.348500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(G, show_shapes = True)","metadata":{"id":"bLm4rHOwnJwO","outputId":"129e033e-854f-46e2-8076-b4679b1a9059","execution":{"iopub.status.busy":"2023-11-26T09:53:50.350788Z","iopub.execute_input":"2023-11-26T09:53:50.351133Z","iopub.status.idle":"2023-11-26T09:53:50.540536Z","shell.execute_reply.started":"2023-11-26T09:53:50.351103Z","shell.execute_reply":"2023-11-26T09:53:50.539680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(D, show_shapes = True)","metadata":{"id":"mxZQyHGNnJwO","outputId":"08421048-3c3a-4b70-b383-04867880d050","execution":{"iopub.status.busy":"2023-11-26T09:53:50.542029Z","iopub.execute_input":"2023-11-26T09:53:50.542351Z","iopub.status.idle":"2023-11-26T09:53:50.662838Z","shell.execute_reply.started":"2023-11-26T09:53:50.542324Z","shell.execute_reply":"2023-11-26T09:53:50.661891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acgan.trainAlgorithm(G, D, GAN)","metadata":{"id":"SwjhvCrwnJwP","outputId":"9e6a1886-41b9-444b-9775-7c939cda8a0b","execution":{"iopub.status.busy":"2023-11-26T09:53:50.664140Z","iopub.execute_input":"2023-11-26T09:53:50.664486Z","iopub.status.idle":"2023-11-26T11:14:16.620524Z","shell.execute_reply.started":"2023-11-26T09:53:50.664451Z","shell.execute_reply":"2023-11-26T11:14:16.619707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G.save('/kaggle/working/generator.h5')","metadata":{"id":"A5PcEPXkaGHz","outputId":"914e9219-e5f0-49f6-c2a9-514f75b18d77","execution":{"iopub.status.busy":"2023-11-26T11:14:16.621589Z","iopub.execute_input":"2023-11-26T11:14:16.621890Z","iopub.status.idle":"2023-11-26T11:14:16.819315Z","shell.execute_reply.started":"2023-11-26T11:14:16.621866Z","shell.execute_reply":"2023-11-26T11:14:16.818307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G = tf.keras.models.load_model('/kaggle/working/generator.h5')","metadata":{"id":"9_Ys4Zy4mygE","outputId":"49d1f34c-cf73-4d1d-e3d1-2b4bd811e08c","execution":{"iopub.status.busy":"2023-11-26T11:56:40.638403Z","iopub.execute_input":"2023-11-26T11:56:40.638892Z","iopub.status.idle":"2023-11-26T11:56:41.228528Z","shell.execute_reply.started":"2023-11-26T11:56:40.638857Z","shell.execute_reply":"2023-11-26T11:56:41.227708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have to make sure that the images that the generator generates are correct, and that they actually include pathological conditions, and this is done by generating a large number of samples, using a neural network to classify the images, and then using the trained neural network, in order to classify the basic images that are included in the basic dataset.","metadata":{"id":"Hn-ZHj3vCOVn"}},{"cell_type":"code","source":"datasetGenerationSize = 30000\nnoize = tf.random.uniform(shape = (datasetGenerationSize, 100), minval = -1, maxval = 1)\nnewlabels = tf.keras.utils.to_categorical(np.random.choice([0, 1], size = (datasetGenerationSize, )), num_classes = 2)","metadata":{"id":"o-j-SeQP9L44","execution":{"iopub.status.busy":"2023-11-26T11:14:17.441706Z","iopub.execute_input":"2023-11-26T11:14:17.442394Z","iopub.status.idle":"2023-11-26T11:14:17.449342Z","shell.execute_reply.started":"2023-11-26T11:14:17.442367Z","shell.execute_reply":"2023-11-26T11:14:17.448406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noize.shape, newlabels.shape","metadata":{"id":"OpMZxDec9L44","outputId":"b9992e0d-386e-49a5-f6d6-4c15df868e27","execution":{"iopub.status.busy":"2023-11-26T11:14:17.450802Z","iopub.execute_input":"2023-11-26T11:14:17.451398Z","iopub.status.idle":"2023-11-26T11:14:17.460132Z","shell.execute_reply.started":"2023-11-26T11:14:17.451371Z","shell.execute_reply":"2023-11-26T11:14:17.459161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(np.argmax(newlabels, axis = 1), return_counts = True)","metadata":{"id":"tNWq4Nf5nFzN","outputId":"b30b9c30-bc3c-4565-ded1-409be905dd1e","execution":{"iopub.status.busy":"2023-11-26T11:14:17.461389Z","iopub.execute_input":"2023-11-26T11:14:17.461699Z","iopub.status.idle":"2023-11-26T11:14:17.474490Z","shell.execute_reply.started":"2023-11-26T11:14:17.461668Z","shell.execute_reply":"2023-11-26T11:14:17.473572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagesGeneration = G.predict([noize, newlabels])\nimagesGeneration.shape","metadata":{"id":"kfcNupOn9L45","outputId":"bf9b91f8-9c85-48cf-dcac-1498ffc718e9","execution":{"iopub.status.busy":"2023-11-26T11:14:17.475924Z","iopub.execute_input":"2023-11-26T11:14:17.476222Z","iopub.status.idle":"2023-11-26T11:14:35.155693Z","shell.execute_reply.started":"2023-11-26T11:14:17.476186Z","shell.execute_reply":"2023-11-26T11:14:35.154702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Samples generated by the generator for each case (healthy person, person with pneumonia).","metadata":{"id":"NArybc1tCc7I"}},{"cell_type":"code","source":"plt.figure(figsize = (12, 12))\nt = np.argmax(newlabels, axis = 1)\nfor i in range(64):\n    plt.subplot(8, 8, (i + 1))\n    plt.imshow(imagesGeneration[i])\n    plt.title(t[i])\nplt.legend()","metadata":{"id":"eI2uH5f-9L45","outputId":"c35afeee-3903-426b-9b5b-4cece15553fb","execution":{"iopub.status.busy":"2023-11-26T11:14:35.156909Z","iopub.execute_input":"2023-11-26T11:14:35.157224Z","iopub.status.idle":"2023-11-26T11:14:44.453791Z","shell.execute_reply.started":"2023-11-26T11:14:35.157198Z","shell.execute_reply":"2023-11-26T11:14:44.452895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to be able to evaluate the images generated by the generating neural network, we can do so by proposing a neural structure dedicated to classifying the images generated by the generating neural network, and then we return to the basic images included in the dataset, and we evaluate the performance of the classified neural network that It was trained on the generated images, in order to see if the learned characteristics of the generated images can give high results on the basic images included in the dataset.","metadata":{"id":"6ZuiXP9_5o4o"}},{"cell_type":"code","source":"basemodel = tf.keras.applications.VGG16(weights = None, input_shape = (64, 64, 3),\n                                        pooling = 'max', include_top = False)\nx = layers.Dropout(0.4)(basemodel.output)\nx = layers.Dense(128,)(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(alpha = 0.2)(x)\nx = layers.Dropout(0.4)(x)\nx = layers.Dense(32,)(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(alpha = 0.2)(x)\nx = layers.Dropout(0.4)(x)\nx = layers.Dense(1, activation = 'sigmoid')(x)\nm = tf.keras.models.Model(inputs = basemodel.input, outputs = x)\nm.compile(loss = 'binary_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001))\nm.summary()","metadata":{"id":"ZOBZ_yIGnk9d","outputId":"507aa8f1-6aeb-45bb-81b3-534c9332811f","execution":{"iopub.status.busy":"2023-11-26T11:14:44.455187Z","iopub.execute_input":"2023-11-26T11:14:44.455523Z","iopub.status.idle":"2023-11-26T11:14:44.798327Z","shell.execute_reply.started":"2023-11-26T11:14:44.455495Z","shell.execute_reply":"2023-11-26T11:14:44.797408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Training the neural network to classify the images generated by the generator.","metadata":{"id":"fCaZ4y-CCohK"}},{"cell_type":"code","source":"history = m.fit(imagesGeneration, np.argmax(newlabels, axis = 1),\n                epochs = 60, batch_size = 64,\n                validation_split = 0.2,\n                callbacks = [tf.keras.callbacks.EarlyStopping(patience = 2, monitor = 'val_loss', mode = 'min',\n                                                              restore_best_weights = True)])","metadata":{"id":"o0wuuo0joZm-","outputId":"81b790d4-ac25-4449-afbd-9d6e5ae46c4d","execution":{"iopub.status.busy":"2023-11-26T11:14:44.799586Z","iopub.execute_input":"2023-11-26T11:14:44.800222Z","iopub.status.idle":"2023-11-26T11:16:57.203875Z","shell.execute_reply.started":"2023-11-26T11:14:44.800193Z","shell.execute_reply":"2023-11-26T11:16:57.203091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7, 6))\nplt.plot(history.history['loss'], label = 'training loss')\nplt.plot(history.history['val_loss'], label = 'validation loss')\nplt.title('Results obtained while training a neural network on images generated by the neural network')\nplt.legend()","metadata":{"id":"SfB58rX2yOCF","outputId":"c7d47317-2d29-459a-e9e8-b856b39626ba","execution":{"iopub.status.busy":"2023-11-26T11:16:57.205019Z","iopub.execute_input":"2023-11-26T11:16:57.205334Z","iopub.status.idle":"2023-11-26T11:16:57.571875Z","shell.execute_reply.started":"2023-11-26T11:16:57.205308Z","shell.execute_reply":"2023-11-26T11:16:57.570791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Now, after training on the images generated by the generator, we will test the neural network on the basic images included in the dataset.","metadata":{"id":"X-JdoB8jC2zn"}},{"cell_type":"markdown","source":"- We will use several measures in the evaluation to study what is the ability of the generative adversarial network to capture the basic features that characterize each class, and whether the second classified network extracted the features included in the generated images.\n- Are the attributes that were extracted from the images generated by the generator, can be used on the original images included in the dataset.\n- This helps in the ability to study what was actually generated, and whether the focus was really on the cases that the X-ray images made him have pneumonia or not.","metadata":{"id":"Mw0ZcgK5DXzF"}},{"cell_type":"code","source":"m.evaluate(images, labels)","metadata":{"id":"FntzezTzv2wp","outputId":"9ed36a82-3c77-41df-961a-dc977c26d6b2","execution":{"iopub.status.busy":"2023-11-26T11:16:57.573063Z","iopub.execute_input":"2023-11-26T11:16:57.573344Z","iopub.status.idle":"2023-11-26T11:17:00.119530Z","shell.execute_reply.started":"2023-11-26T11:16:57.573321Z","shell.execute_reply":"2023-11-26T11:17:00.118569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = tf.squeeze(m.predict(images))\ny_pred.shape","metadata":{"id":"E5M1GhDPv9uv","outputId":"54859610-83c3-42c5-8cac-fe9a46cee314","execution":{"iopub.status.busy":"2023-11-26T11:17:00.120623Z","iopub.execute_input":"2023-11-26T11:17:00.120950Z","iopub.status.idle":"2023-11-26T11:17:02.325339Z","shell.execute_reply.started":"2023-11-26T11:17:00.120926Z","shell.execute_reply":"2023-11-26T11:17:02.324431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = y_pred >= 0.5\ny_pred = np.array(y_pred, dtype = 'int32')\ny_pred","metadata":{"id":"oJE6RnYBw2A-","outputId":"99c7c855-0034-4ee0-ee3a-a388be7e2548","execution":{"iopub.status.busy":"2023-11-26T11:17:02.326583Z","iopub.execute_input":"2023-11-26T11:17:02.326953Z","iopub.status.idle":"2023-11-26T11:17:02.334863Z","shell.execute_reply.started":"2023-11-26T11:17:02.326920Z","shell.execute_reply":"2023-11-26T11:17:02.333963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_pred, labels)*100","metadata":{"id":"rrVgeVC0wB5u","outputId":"c2ae8c00-bf60-4e7b-9295-2f68e8237680","execution":{"iopub.status.busy":"2023-11-26T11:17:02.336166Z","iopub.execute_input":"2023-11-26T11:17:02.336571Z","iopub.status.idle":"2023-11-26T11:17:02.346259Z","shell.execute_reply.started":"2023-11-26T11:17:02.336530Z","shell.execute_reply":"2023-11-26T11:17:02.345271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_pred, labels))","metadata":{"id":"B-jOp3A6wHTl","outputId":"6b849621-f18b-49be-996c-85f90a26fc6e","execution":{"iopub.status.busy":"2023-11-26T11:17:02.351797Z","iopub.execute_input":"2023-11-26T11:17:02.352362Z","iopub.status.idle":"2023-11-26T11:17:02.373550Z","shell.execute_reply.started":"2023-11-26T11:17:02.352337Z","shell.execute_reply":"2023-11-26T11:17:02.372656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\ncm = confusion_matrix(y_pred, labels)\ncm","metadata":{"id":"dHoGZuH90cVG","outputId":"62e961bb-361e-400c-faa3-c84940f30dd5","execution":{"iopub.status.busy":"2023-11-26T11:17:02.374540Z","iopub.execute_input":"2023-11-26T11:17:02.374827Z","iopub.status.idle":"2023-11-26T11:17:02.542008Z","shell.execute_reply.started":"2023-11-26T11:17:02.374803Z","shell.execute_reply":"2023-11-26T11:17:02.540968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncmObject = pd.DataFrame(cm , index = ['NORMAL', 'PNEUMONIA'],\n                        columns = ['NORMAL', 'PNEUMONIA'])\ncmObject.head()","metadata":{"id":"iuOwDQOaggOc","outputId":"2333edd8-f133-4e73-a857-c69e3f41f695","execution":{"iopub.status.busy":"2023-11-26T11:17:02.543281Z","iopub.execute_input":"2023-11-26T11:17:02.543574Z","iopub.status.idle":"2023-11-26T11:17:02.560335Z","shell.execute_reply.started":"2023-11-26T11:17:02.543549Z","shell.execute_reply":"2023-11-26T11:17:02.559343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('f1_score: {}, recall_score: {}, precision_score: {}'.format(f1_score(y_pred, labels)*100,\n                                                                   recall_score(y_pred, labels)*100,\n                                                                   precision_score(y_pred, labels)*100))","metadata":{"id":"QgF0Hmua0itl","outputId":"35c0ec25-601a-4764-cda4-e23f287c599b","execution":{"iopub.status.busy":"2023-11-26T11:17:02.561664Z","iopub.execute_input":"2023-11-26T11:17:02.562237Z","iopub.status.idle":"2023-11-26T11:17:02.578943Z","shell.execute_reply.started":"2023-11-26T11:17:02.562205Z","shell.execute_reply":"2023-11-26T11:17:02.578057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cmObject, annot = True, cmap=\"Blues\")","metadata":{"id":"KfrUU_SPxcrE","outputId":"87c2b7f9-f82d-4a84-c42e-fc5fded167ca","execution":{"iopub.status.busy":"2023-11-26T11:17:02.579985Z","iopub.execute_input":"2023-11-26T11:17:02.580251Z","iopub.status.idle":"2023-11-26T11:17:02.875078Z","shell.execute_reply.started":"2023-11-26T11:17:02.580228Z","shell.execute_reply":"2023-11-26T11:17:02.874009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In the end, we can see that we have reached a neural network that is able to generate accurate images.\nBut the slight variation in the accuracy of the classification for each class is due to the fact that we need more training time for the generative adversarial network, which helps to focus more on the characteristics of each class (because the number of samples in the basic dataset is different for each class (the healthy case, pneumonia)).","metadata":{"id":"Y6m4LBLxEGrI"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom PIL import Image\n\n\n\n# Set parameters\ndatasetGenerationSize = 30000\noutput_folder = '/kaggle/output/working/generatedImages'  # Note the change in the path\nos.makedirs(output_folder, exist_ok=True)\n\n# Generate random noise\nnoize = tf.random.uniform(shape=(datasetGenerationSize, 100), minval=-1, maxval=1)\n\n# Generate random labels\nnewlabels = tf.keras.utils.to_categorical(np.random.choice([0, 1], size=(datasetGenerationSize, )), num_classes=2)\n\n# Check class distribution\nprint(\"Class Distribution:\", np.unique(np.argmax(newlabels, axis=1), return_counts=True))\n\n# Generate images using the generator\nimagesGeneration = G.predict([noize, newlabels])\n\n# Save generated images to the Kaggle dataset output directory\nfor i, image in enumerate(imagesGeneration):\n    class_label = np.argmax(newlabels[i])\n    image_path = os.path.join(output_folder, f'image_{i}_class_{class_label}.png')\n    Image.fromarray((image * 255).astype(np.uint8)).save(image_path)\n\nprint(f\"Generated images saved to {output_folder}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:57:15.923116Z","iopub.execute_input":"2023-11-26T11:57:15.924003Z","iopub.status.idle":"2023-11-26T11:57:16.799556Z","shell.execute_reply.started":"2023-11-26T11:57:15.923956Z","shell.execute_reply":"2023-11-26T11:57:16.798569Z"},"trusted":true},"execution_count":null,"outputs":[]}]}